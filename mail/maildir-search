#!/usr/bin/python

## maildir-search

## tkooda : 2013-10-12 : 


## algorithm:
##  - quickly search Maildirs for new email messages
##  - scan email messages
##    - skip email messages that match a To/From/CC/BCC/Resent-From/Resent-To regex
##    - display messages that contain a matching regex (that don't also match the ignore regex) and
##      - prompt to ignore that message in the future

## config example (~/.config/maildir-search.cfg) :
## 
##   { "regex_address_skip": "((asmith|adam.smith)@example.com|adam@gmail.com)",
##     "regex_message_match": "([^a-z]|^)(adam|smith)([^a-z]|s[^a-z]|$)",
##     "regex_message_ignore": "(blacksmith|smithers)" }
## 

## usage example:
##   maildir-search 0 ~/.Maildir/


import os
import sys
import re
import email
import tempfile
import time
import subprocess
import json


def do_debug( level, *args ):
    try:
        if level <= int( os.getenv( "DEBUG" ) ):
            print >>sys.stderr, "DEBUG(%d): %s" % ( level, " : ".join( str(x) for x in args ) )
    except:
        pass


def read_email( path ):
    fp = open( path, 'rb' )
    msg = email.message_from_file( fp )
    fp.close()
    return msg


def is_my_email( msg ):
    for header in [ "To", "From", "Cc", "Bcc", "Resent-From", "Resent-To" ]:
        if not header in msg:
            continue
        if pattern_address_skip.search( msg[ header ] ):
            return True
    return False


def is_bulk_email( msg ):
    for header in [ "List-Unsubscribe" ]:
        if header in msg:
            return True
    return False


def get_message_id( msg ):
    if "Message-ID" in msg:
        return msg[ "Message-ID" ]
    return False


## return all (appended; even nested in many MIME multiparts) text AND html parts (appended together for searching); as some MUC's will allow them to differ (even though they're "multipart/alternative"!)
def get_message_body( msg ):
    main_type = msg.get_content_maintype()
    if main_type != "multipart":
        return msg.get_payload()
    
    # is main_type is multipart, recurse down every multipart pieces..
    msg_body_str = ""
    for part in msg.get_payload():
        part_type = part.get_content_maintype()
        if part_type == "multipart":
            # handle nested MIME multipart messages, recurse..
            msg_body_str += get_message_body( part )
        elif part_type == "text" or part_type == "html": # return BOTH text AND html for searching, some MUC's will allow them to differ!
            msg_body_str += part.get_payload()
    
    return msg_body_str


def write_set_to_file( s, f ):
    fp, fn = tempfile.mkstemp( suffix = ".tmp",
                               prefix = f + "." )
    for item in s:
        os.write( fp, "%s\n" % item )
    os.close( fp )
    os.rename( os.path.join( os.path.dirname( f ), fn), f )


def create_missing( f ):
    if os.path.exists( f ):
        return
    fp = open( f, "w+" )
    fp.close()


def prompt_answer( f ):
    ans = False
    while ans != "y" and ans != "n" and ans != "":
        ans = raw_input( 'ignore "%s" ? [Y/n] ' % f )
    if ans == "y" or ans == "":
        return True
    return False


def get_config():
    path_config = os.path.join( os.path.expanduser( "~" ), ".config/maildir-search.cfg" )
    fp = open( path_config, "r" )
    config = json.load( fp )
    fp.close()
    return config



if __name__ == '__main__':
    if len( sys.argv ) < 3:
        print >>sys.stderr, "usage: %s <minutes> <maildirs..>" % os.path.basename( sys.argv[0] )
        sys.exit( 2 )
    
    minutes = int( sys.argv[1] ) # ignore files older than these minutes, 0 to not ignore any
    
    config = get_config()

    pattern_address_skip = re.compile( config[ "regex_address_skip" ], re.M | re.I )
    pattern_message_match = re.compile( config[ "regex_message_match" ], re.M | re.I )
    pattern_message_ignore = re.compile( config[ "regex_message_ignore" ], re.M | re.I )
    
    if os.getenv( "DEBUG" ):
        path_dir_cache = "/tmp"
    else:
        path_dir_cache = os.path.join( os.path.expanduser( "~" ), ".cache" )
    
    path_file_skip = os.path.join( path_dir_cache, "maildir-search_skip.txt" )
    create_missing( path_file_skip )
    set_of_skips = set( line.strip() for line in open( path_file_skip ) )
    print "loaded set_of_skips:", len( set_of_skips )
    
    path_file_hit = os.path.join( path_dir_cache, "maildir-search_hit.txt" )
    create_missing( path_file_hit )
    set_of_hits = set( line.strip() for line in open( path_file_hit ) )
    print "loaded set_of_hits:", len( set_of_hits )
    
    path_file_miss = os.path.join( path_dir_cache, "maildir-search_miss.txt" )
    create_missing( path_file_miss )
    set_of_misses = set( line.strip() for line in open( path_file_miss ) )
    print "loaded set_of_misses:", len( set_of_misses )
    
    path_file_message_id = os.path.join( path_dir_cache, "maildir-search_message_id.txt" )
    create_missing( path_file_message_id )
    set_of_message_ids = set( line.strip() for line in open( path_file_message_id ) )
    print "loaded set_of_message_ids:", len( set_of_message_ids )
    
    hits_tocheck = []
    
    count_new_skip = 0
    count_new_hit = 0
    count_new_miss = 0
    count_new_message_id = 0
    count_ignored_dir = 0
    count_ignored_file = 0
    count_skipped_message_ids = 0
    count_examined_file = 0
    
    
    ## walk down directory tree ..
    for path in sys.argv[ 2: ]:
        print "searching:", path
        for root, dirs, files in os.walk( path, topdown=True ):
            try:
                for d in dirs:
                    d_path = os.path.join( root, d )
                    if minutes:
                        if time.time() - os.path.getmtime( d_path ) > minutes * 60: # ignore directory if older than $minutes
                            do_debug( 5, "ignoring dir", d_path )
                            count_ignored_dir += 1
                            continue
                
                for f in files:
                    f_path = os.path.join( root, f )
                
                    if minutes:
                        if time.time() - os.path.getmtime( f_path ) > minutes * 60: # ignore file if older than $minutes
                            count_ignored_file += 1
                            continue
                
	                f_base = f.split( ":", 1 )[0]
	                
	                if f_base in set_of_skips:
	                    do_debug( 4, "old skip", f_base )
	                    continue
	                
	                if f_base in set_of_hits:
	                    do_debug( 4, "old hit", f_base )
	                    continue
	                
	                if f_base in set_of_misses:
	                    do_debug( 4, "old miss", f_base )
	                    continue
	                
	                msg = read_email( f_path )
	                count_examined_file += 1
	                body = str( get_message_body( msg ) )
                        
	                if is_my_email( msg ):
	                    ## this email was sent to/from me, skip it ..
	                    do_debug( 3, "new skip-mine", f_base )
	                    count_new_skip += 1
	                    set_of_skips.add( f_base )
	                elif is_bulk_email( msg ):
	                    ## this email is bulk email, skip it ..
	                    do_debug( 3, "new skip-bulk", f_base )
	                    count_new_skip += 1
	                    set_of_skips.add( f_base )
	                else:
                            m = pattern_message_match.search( body )
                            if m:
                                ## this email matches my regex ..
                                
                                ## check if we're supposed to ignore this regex match..
                                match_plus_bookend_chars = "".join( m.groups() )
                                do_debug( 3, "pattern_message_match", match_plus_bookend_chars )
                                if pattern_message_ignore.search( "".join( m.groups() ) ):
                                    do_debug( 3, "ignoring new hit", match_plus_bookend_chars )
                                else:
                                    do_debug( 3, "new hit", f_base )
                                    if f_path not in hits_tocheck:
                                        hits_tocheck.append( f_path )
                                
                            else:
                                ## this email wasn't sent to/from me, an doesn't match my regex ..
                                do_debug( 3, "new miss", f_base )
                                count_new_miss += 1
                                set_of_misses.add( f_base )
                            
	    except:
                pass # silently ignore errors (e.g. file moved)
    
    
    if count_ignored_dir:
        print "ignored dirs: %d" % count_ignored_dir
    
    if count_ignored_file:
        print "ignored files: %d" % count_ignored_file
    
    if count_examined_file:
        print "count_examined files: %d" % count_examined_file
    
    if count_new_miss:
        write_set_to_file( set_of_misses, path_file_miss )
        print "saved set_of_misses: %d new, %d total" % ( count_new_miss, len( set_of_misses ) )

    if count_new_skip:
        write_set_to_file( set_of_skips, path_file_skip )
        print "saved set_of_skips: %d new, %d total" % ( count_new_skip, len( set_of_skips ) )
    
    if hits_tocheck:
        count_new_hit = 0

        for path_check in hits_tocheck:
            ## automatically ignore messages with the same message-id of other messages we've already ignored
            try:
                msg = read_email( path_check )
            except IOError: # if file moves before we get to it, just quietly ignore it and check the next one
                continue
            
            message_id = get_message_id( msg )
            if message_id in set_of_message_ids: # auto-ignore this already ignored message-id
                base_check = os.path.basename( path_check ).split( ":", 1 )[0]
                set_of_hits.add( base_check )
                count_new_hit += 1
                count_skipped_message_ids += 1
                continue
            ## end: ignoring message with same message-id of other messages we've already ignored
            
            
            less_regex = "".join( re.split( "\(\?!.+?\)", config[ "regex_message_match" ] ) ) # remove any negative lookahead assertions that aren't supported by less's regex (as long as they don't also contain their own parens)
            subprocess.call( [ "less", "-p", less_regex, path_check ] )
            
            if prompt_answer( path_check ):
                base_check = os.path.basename( path_check ).split( ":", 1 )[0]
                set_of_hits.add( base_check )
                count_new_hit += 1
                
                # also ignore future occurances of this same message-id
                try:
                    msg = read_email( path_check )
                except IOError: # if file moves before we get to it, just quietly ignore it and check the next one
                    continue
                
                message_id = get_message_id( msg )
                set_of_message_ids.add( message_id )
                count_new_message_id += 1
        
        
        if count_skipped_message_ids:
            print "skipped messages with seen message-ids: %d" % count_skipped_message_ids
        
        if count_new_message_id:
            write_set_to_file( set_of_message_ids, path_file_message_id )
            print "saved set_of_message_ids: %d new, %d total" % ( count_new_message_id, len( set_of_message_ids ) )
        
        if count_new_hit:
            write_set_to_file( set_of_hits, path_file_hit )
            print "saved set_of_hits: %d new, %d total" % ( count_new_hit, len( set_of_hits ) )

